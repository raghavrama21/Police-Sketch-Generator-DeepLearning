{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64c8a000",
      "metadata": {
        "id": "64c8a000"
      },
      "source": [
        "## BAX-423 Big Data Analytics\n",
        "## Data Dinosaurs: Kangjian (James) Gao, Raghav Rama Bhadran, Sahiti Sukhavasi, Trishal Jadhav\n",
        "## Final Project - Criminal Sketch Generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_uv6NiIDQq2",
        "outputId": "ce9846a7-4fc3-4cc2-f571-1b67482f1a40"
      },
      "id": "E_uv6NiIDQq2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2e0be27e",
      "metadata": {
        "id": "2e0be27e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba4fe20-1011-4c08-b148-a5b7d3e78927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "38628d9a",
      "metadata": {
        "id": "38628d9a"
      },
      "outputs": [],
      "source": [
        "# Loading libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_folder, feature_data, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.img_list = glob.glob(self.image_folder + \"/*.jpg\")\n",
        "        self.feature_data = feature_data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_folder)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        image = Image.open(image_path)\n",
        "        feature = self.feature_data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, feature"
      ],
      "metadata": {
        "id": "ywkFyU0KsKtn"
      },
      "id": "ywkFyU0KsKtn",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, feature_size, output_channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc = nn.Linear(input_size + feature_size, 128*16*16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.deconv = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(64)\n",
        "        self.deconv2 = nn.ConvTranspose2d(64, output_channels, kernel_size=4, stride=2, padding=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, noise, features):\n",
        "        x = torch.cat((noise, features), dim=1)\n",
        "        x = x.to(torch.float32)\n",
        "        x = self.fc(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1, 128, 16, 16)\n",
        "        x = self.deconv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FB_oALAwsrJJ"
      },
      "id": "FB_oALAwsrJJ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv = nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(128)\n",
        "        self.fc = nn.Linear(128*16*16, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1, 128*16*16)\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "K9y937Q-sv3U"
      },
      "id": "K9y937Q-sv3U",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GAN model\n",
        "class GAN(nn.Module):\n",
        "    def __init__(self, input_size, feature_size, output_channels):\n",
        "        super(GAN, self).__init__()\n",
        "        self.generator = Generator(input_size, feature_size, output_channels)\n",
        "        self.discriminator = Discriminator(output_channels)\n",
        "\n",
        "    def forward(self, noise, features):\n",
        "        generated_images = self.generator(noise, features)\n",
        "        return generated_images"
      ],
      "metadata": {
        "id": "snvGqT4Zsy80"
      },
      "id": "snvGqT4Zsy80",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop\n",
        "def train_gan(generator, discriminator, dataloader, num_epochs, device):\n",
        "    criterion = nn.BCELoss()\n",
        "    generator_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_idx, (images, features) in enumerate(dataloader):\n",
        "            batch_size = images.size(0)\n",
        "            images = images.to(device)\n",
        "            features = features.to(device)\n",
        "\n",
        "            # Generate random noise vector\n",
        "            noise = torch.randn(batch_size, input_size).to(device)\n",
        "\n",
        "            # Update discriminator\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            real_labels = torch.ones(batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "            real_outputs = discriminator(images)\n",
        "            real_loss = criterion(real_outputs, real_labels)\n",
        "            real_loss.backward()\n",
        "\n",
        "            generated_images = generator(noise, features)\n",
        "            fake_outputs = discriminator(generated_images.detach())\n",
        "            fake_loss = criterion(fake_outputs, fake_labels)\n",
        "            fake_loss.backward()\n",
        "\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "            # Update generator\n",
        "            generator_optimizer.zero_grad()\n",
        "            fake_outputs = discriminator(generated_images)\n",
        "            generator_loss = criterion(fake_outputs, real_labels)\n",
        "            generator_loss.backward()\n",
        "            generator_optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], \"\n",
        "                      f\"Discriminator Loss: {real_loss+fake_loss}, Generator Loss: {generator_loss}\")"
      ],
      "metadata": {
        "id": "RwPaXGBcs6_0"
      },
      "id": "RwPaXGBcs6_0",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify paths and parameters\n",
        "image_folder = 'drive/MyDrive/Big Data/Images'\n",
        "feature_file = 'drive/MyDrive/Big Data/Features.csv'\n",
        "input_size = 100  # Size of the input noise vector\n",
        "feature_size = 45  # Size of the input feature vector\n",
        "output_channels = 3  # Number of image channels (e.g., 1 for grayscale, 3 for RGB)\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize images to a uniform size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Defining function to load features\n",
        "def load_features(file_path, has_header=True):\n",
        "    with open(file_path, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        if has_header:\n",
        "            header = next(reader)  # Skip the header row\n",
        "        features = [list(map(float, row)) for row in reader]\n",
        "    return np.array(features)\n",
        "\n",
        "# Load dataset and create a dataloader\n",
        "feature_data = load_features(feature_file)  # Load feature data\n",
        "# Create instance of CustomDataset\n",
        "dataset = CustomDataset(image_folder, feature_data, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "wHL271IYs8TC"
      },
      "id": "wHL271IYs8TC",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the GAN model\n",
        "gan = GAN(input_size, feature_size, output_channels).to(device)\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan.generator, gan.discriminator, dataloader, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lue1G9SEl_j",
        "outputId": "305744bd-7511-4dda-9381-5ca265bfc8ba"
      },
      "id": "_Lue1G9SEl_j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/1], Discriminator Loss: 1.4057718515396118, Generator Loss: 2.6958160400390625\n",
            "Epoch [2/1000], Batch [1/1], Discriminator Loss: 0.7171617150306702, Generator Loss: 3.504302501678467\n",
            "Epoch [3/1000], Batch [1/1], Discriminator Loss: 0.36753398180007935, Generator Loss: 4.035143852233887\n",
            "Epoch [4/1000], Batch [1/1], Discriminator Loss: 0.2454102784395218, Generator Loss: 4.126587390899658\n",
            "Epoch [5/1000], Batch [1/1], Discriminator Loss: 0.2208651751279831, Generator Loss: 4.032221794128418\n",
            "Epoch [6/1000], Batch [1/1], Discriminator Loss: 0.24453957378864288, Generator Loss: 3.98093318939209\n",
            "Epoch [7/1000], Batch [1/1], Discriminator Loss: 0.22359494864940643, Generator Loss: 4.125439167022705\n",
            "Epoch [8/1000], Batch [1/1], Discriminator Loss: 0.20094603300094604, Generator Loss: 4.21767520904541\n",
            "Epoch [9/1000], Batch [1/1], Discriminator Loss: 0.18327823281288147, Generator Loss: 4.265844821929932\n",
            "Epoch [10/1000], Batch [1/1], Discriminator Loss: 0.17152139544487, Generator Loss: 4.355055809020996\n",
            "Epoch [11/1000], Batch [1/1], Discriminator Loss: 0.14293041825294495, Generator Loss: 4.456440448760986\n",
            "Epoch [12/1000], Batch [1/1], Discriminator Loss: 0.14583025872707367, Generator Loss: 4.475689888000488\n",
            "Epoch [13/1000], Batch [1/1], Discriminator Loss: 0.12859569489955902, Generator Loss: 4.587428569793701\n",
            "Epoch [14/1000], Batch [1/1], Discriminator Loss: 0.11841277778148651, Generator Loss: 4.626769542694092\n",
            "Epoch [15/1000], Batch [1/1], Discriminator Loss: 0.12275616824626923, Generator Loss: 4.69651460647583\n",
            "Epoch [16/1000], Batch [1/1], Discriminator Loss: 0.10957389324903488, Generator Loss: 4.7906951904296875\n",
            "Epoch [17/1000], Batch [1/1], Discriminator Loss: 0.10861733555793762, Generator Loss: 4.810782432556152\n",
            "Epoch [18/1000], Batch [1/1], Discriminator Loss: 0.09679006040096283, Generator Loss: 4.864141941070557\n",
            "Epoch [19/1000], Batch [1/1], Discriminator Loss: 0.09309424459934235, Generator Loss: 4.863243579864502\n",
            "Epoch [20/1000], Batch [1/1], Discriminator Loss: 0.10176726430654526, Generator Loss: 4.942630767822266\n",
            "Epoch [21/1000], Batch [1/1], Discriminator Loss: 0.08903194963932037, Generator Loss: 5.0583176612854\n",
            "Epoch [22/1000], Batch [1/1], Discriminator Loss: 0.08242417871952057, Generator Loss: 5.061702251434326\n",
            "Epoch [23/1000], Batch [1/1], Discriminator Loss: 0.08450595289468765, Generator Loss: 5.062893867492676\n",
            "Epoch [24/1000], Batch [1/1], Discriminator Loss: 0.07876355946063995, Generator Loss: 5.090871334075928\n",
            "Epoch [25/1000], Batch [1/1], Discriminator Loss: 0.08094696700572968, Generator Loss: 5.160295009613037\n",
            "Epoch [26/1000], Batch [1/1], Discriminator Loss: 0.0786961168050766, Generator Loss: 5.224291801452637\n",
            "Epoch [27/1000], Batch [1/1], Discriminator Loss: 0.07374074310064316, Generator Loss: 5.270328998565674\n",
            "Epoch [28/1000], Batch [1/1], Discriminator Loss: 0.06734051555395126, Generator Loss: 5.250253200531006\n",
            "Epoch [29/1000], Batch [1/1], Discriminator Loss: 0.06802339851856232, Generator Loss: 5.228914260864258\n",
            "Epoch [30/1000], Batch [1/1], Discriminator Loss: 0.0707622841000557, Generator Loss: 5.27674674987793\n",
            "Epoch [31/1000], Batch [1/1], Discriminator Loss: 0.06734289973974228, Generator Loss: 5.359652519226074\n",
            "Epoch [32/1000], Batch [1/1], Discriminator Loss: 0.06521675735712051, Generator Loss: 5.388851642608643\n",
            "Epoch [33/1000], Batch [1/1], Discriminator Loss: 0.059258464723825455, Generator Loss: 5.35222864151001\n",
            "Epoch [34/1000], Batch [1/1], Discriminator Loss: 0.06563262641429901, Generator Loss: 5.342630863189697\n",
            "Epoch [35/1000], Batch [1/1], Discriminator Loss: 0.06531596183776855, Generator Loss: 5.47214937210083\n",
            "Epoch [36/1000], Batch [1/1], Discriminator Loss: 0.060376062989234924, Generator Loss: 5.469776153564453\n",
            "Epoch [37/1000], Batch [1/1], Discriminator Loss: 0.058700092136859894, Generator Loss: 5.447080612182617\n",
            "Epoch [38/1000], Batch [1/1], Discriminator Loss: 0.06533389538526535, Generator Loss: 5.51875638961792\n",
            "Epoch [39/1000], Batch [1/1], Discriminator Loss: 0.056585006415843964, Generator Loss: 5.559369087219238\n",
            "Epoch [40/1000], Batch [1/1], Discriminator Loss: 0.05771026760339737, Generator Loss: 5.477362155914307\n",
            "Epoch [41/1000], Batch [1/1], Discriminator Loss: 0.06086613982915878, Generator Loss: 5.564012050628662\n",
            "Epoch [42/1000], Batch [1/1], Discriminator Loss: 0.058033090084791183, Generator Loss: 5.5944366455078125\n",
            "Epoch [43/1000], Batch [1/1], Discriminator Loss: 0.05375976115465164, Generator Loss: 5.4866743087768555\n",
            "Epoch [44/1000], Batch [1/1], Discriminator Loss: 0.058834515511989594, Generator Loss: 5.568599700927734\n",
            "Epoch [45/1000], Batch [1/1], Discriminator Loss: 0.05641317367553711, Generator Loss: 5.6296539306640625\n",
            "Epoch [46/1000], Batch [1/1], Discriminator Loss: 0.05301336199045181, Generator Loss: 5.527980804443359\n",
            "Epoch [47/1000], Batch [1/1], Discriminator Loss: 0.05278981849551201, Generator Loss: 5.586948871612549\n",
            "Epoch [48/1000], Batch [1/1], Discriminator Loss: 0.04639100283384323, Generator Loss: 5.546814441680908\n",
            "Epoch [49/1000], Batch [1/1], Discriminator Loss: 0.04975961893796921, Generator Loss: 5.555222511291504\n",
            "Epoch [50/1000], Batch [1/1], Discriminator Loss: 0.045804161578416824, Generator Loss: 5.5301194190979\n",
            "Epoch [51/1000], Batch [1/1], Discriminator Loss: 0.047783754765987396, Generator Loss: 5.586279392242432\n",
            "Epoch [52/1000], Batch [1/1], Discriminator Loss: 0.04665600135922432, Generator Loss: 5.570144176483154\n",
            "Epoch [53/1000], Batch [1/1], Discriminator Loss: 0.048596952110528946, Generator Loss: 5.619080543518066\n",
            "Epoch [54/1000], Batch [1/1], Discriminator Loss: 0.043868690729141235, Generator Loss: 5.503248691558838\n",
            "Epoch [55/1000], Batch [1/1], Discriminator Loss: 0.047445982694625854, Generator Loss: 5.737741470336914\n",
            "Epoch [56/1000], Batch [1/1], Discriminator Loss: 0.04477325826883316, Generator Loss: 5.4166669845581055\n",
            "Epoch [57/1000], Batch [1/1], Discriminator Loss: 0.04851255193352699, Generator Loss: 5.76757287979126\n",
            "Epoch [58/1000], Batch [1/1], Discriminator Loss: 0.04534407705068588, Generator Loss: 5.508084297180176\n",
            "Epoch [59/1000], Batch [1/1], Discriminator Loss: 0.04674344137310982, Generator Loss: 5.737250328063965\n",
            "Epoch [60/1000], Batch [1/1], Discriminator Loss: 0.044772014021873474, Generator Loss: 5.416365146636963\n",
            "Epoch [61/1000], Batch [1/1], Discriminator Loss: 0.04814582318067551, Generator Loss: 5.903681755065918\n",
            "Epoch [62/1000], Batch [1/1], Discriminator Loss: 0.04316314682364464, Generator Loss: 5.174330234527588\n",
            "Epoch [63/1000], Batch [1/1], Discriminator Loss: 0.050407301634550095, Generator Loss: 6.160626411437988\n",
            "Epoch [64/1000], Batch [1/1], Discriminator Loss: 0.04370611160993576, Generator Loss: 4.989115238189697\n",
            "Epoch [65/1000], Batch [1/1], Discriminator Loss: 0.05607742816209793, Generator Loss: 6.333184242248535\n",
            "Epoch [66/1000], Batch [1/1], Discriminator Loss: 0.05091572552919388, Generator Loss: 4.625335693359375\n",
            "Epoch [67/1000], Batch [1/1], Discriminator Loss: 0.08394698798656464, Generator Loss: 7.696197032928467\n",
            "Epoch [68/1000], Batch [1/1], Discriminator Loss: 0.1941937953233719, Generator Loss: 2.1313705444335938\n",
            "Epoch [69/1000], Batch [1/1], Discriminator Loss: 0.6653132438659668, Generator Loss: 14.26148796081543\n",
            "Epoch [70/1000], Batch [1/1], Discriminator Loss: 6.348875522613525, Generator Loss: 5.9023756980896\n",
            "Epoch [71/1000], Batch [1/1], Discriminator Loss: 0.03747357055544853, Generator Loss: 2.786879777908325\n",
            "Epoch [72/1000], Batch [1/1], Discriminator Loss: 0.7287639379501343, Generator Loss: 11.4570894241333\n",
            "Epoch [73/1000], Batch [1/1], Discriminator Loss: 0.7348167896270752, Generator Loss: 6.904515266418457\n",
            "Epoch [74/1000], Batch [1/1], Discriminator Loss: 0.025175921618938446, Generator Loss: 3.701392650604248\n",
            "Epoch [75/1000], Batch [1/1], Discriminator Loss: 0.4842280447483063, Generator Loss: 9.139911651611328\n",
            "Epoch [76/1000], Batch [1/1], Discriminator Loss: 0.3989829421043396, Generator Loss: 5.366494655609131\n",
            "Epoch [77/1000], Batch [1/1], Discriminator Loss: 0.0959964469075203, Generator Loss: 3.970777988433838\n",
            "Epoch [78/1000], Batch [1/1], Discriminator Loss: 0.28901970386505127, Generator Loss: 7.857333660125732\n",
            "Epoch [79/1000], Batch [1/1], Discriminator Loss: 0.4272133409976959, Generator Loss: 2.806487560272217\n",
            "Epoch [80/1000], Batch [1/1], Discriminator Loss: 0.5671240091323853, Generator Loss: 8.846271514892578\n",
            "Epoch [81/1000], Batch [1/1], Discriminator Loss: 0.666260838508606, Generator Loss: 3.135321855545044\n",
            "Epoch [82/1000], Batch [1/1], Discriminator Loss: 0.49259862303733826, Generator Loss: 7.084149360656738\n",
            "Epoch [83/1000], Batch [1/1], Discriminator Loss: 0.2678172290325165, Generator Loss: 4.876779079437256\n",
            "Epoch [84/1000], Batch [1/1], Discriminator Loss: 0.16115379333496094, Generator Loss: 3.6910383701324463\n",
            "Epoch [85/1000], Batch [1/1], Discriminator Loss: 0.3096665143966675, Generator Loss: 6.628571510314941\n",
            "Epoch [86/1000], Batch [1/1], Discriminator Loss: 0.7531889081001282, Generator Loss: 0.2403503954410553\n",
            "Epoch [87/1000], Batch [1/1], Discriminator Loss: 2.665836811065674, Generator Loss: 10.624755859375\n",
            "Epoch [88/1000], Batch [1/1], Discriminator Loss: 3.1415717601776123, Generator Loss: 3.9634528160095215\n",
            "Epoch [89/1000], Batch [1/1], Discriminator Loss: 0.21332141757011414, Generator Loss: 1.9531019926071167\n",
            "Epoch [90/1000], Batch [1/1], Discriminator Loss: 0.7285408973693848, Generator Loss: 6.373560905456543\n",
            "Epoch [91/1000], Batch [1/1], Discriminator Loss: 0.8123957514762878, Generator Loss: 3.3332951068878174\n",
            "Epoch [92/1000], Batch [1/1], Discriminator Loss: 0.3332377076148987, Generator Loss: 2.6129961013793945\n",
            "Epoch [93/1000], Batch [1/1], Discriminator Loss: 0.47524991631507874, Generator Loss: 5.134394645690918\n",
            "Epoch [94/1000], Batch [1/1], Discriminator Loss: 0.646736204624176, Generator Loss: 1.7594670057296753\n",
            "Epoch [95/1000], Batch [1/1], Discriminator Loss: 0.7604101896286011, Generator Loss: 5.803687572479248\n",
            "Epoch [96/1000], Batch [1/1], Discriminator Loss: 0.8438207507133484, Generator Loss: 2.1915814876556396\n",
            "Epoch [97/1000], Batch [1/1], Discriminator Loss: 0.5321123600006104, Generator Loss: 4.22698450088501\n",
            "Epoch [98/1000], Batch [1/1], Discriminator Loss: 0.33613812923431396, Generator Loss: 3.2654244899749756\n",
            "Epoch [99/1000], Batch [1/1], Discriminator Loss: 0.3260989189147949, Generator Loss: 3.0618255138397217\n",
            "Epoch [100/1000], Batch [1/1], Discriminator Loss: 0.3612135648727417, Generator Loss: 3.557818651199341\n",
            "Epoch [101/1000], Batch [1/1], Discriminator Loss: 0.3906485140323639, Generator Loss: 2.1437580585479736\n",
            "Epoch [102/1000], Batch [1/1], Discriminator Loss: 0.5555939674377441, Generator Loss: 5.320607662200928\n",
            "Epoch [103/1000], Batch [1/1], Discriminator Loss: 0.9493876695632935, Generator Loss: 0.6779899597167969\n",
            "Epoch [104/1000], Batch [1/1], Discriminator Loss: 1.2826957702636719, Generator Loss: 6.405167102813721\n",
            "Epoch [105/1000], Batch [1/1], Discriminator Loss: 1.0829026699066162, Generator Loss: 3.7541520595550537\n",
            "Epoch [106/1000], Batch [1/1], Discriminator Loss: 0.24708376824855804, Generator Loss: 1.9287210702896118\n",
            "Epoch [107/1000], Batch [1/1], Discriminator Loss: 0.4870513379573822, Generator Loss: 4.347107887268066\n",
            "Epoch [108/1000], Batch [1/1], Discriminator Loss: 0.3269123136997223, Generator Loss: 3.5835540294647217\n",
            "Epoch [109/1000], Batch [1/1], Discriminator Loss: 0.2917952239513397, Generator Loss: 2.431550979614258\n",
            "Epoch [110/1000], Batch [1/1], Discriminator Loss: 0.41826605796813965, Generator Loss: 3.931273937225342\n",
            "Epoch [111/1000], Batch [1/1], Discriminator Loss: 0.4202621579170227, Generator Loss: 2.528519630432129\n",
            "Epoch [112/1000], Batch [1/1], Discriminator Loss: 0.4148673415184021, Generator Loss: 3.24527907371521\n",
            "Epoch [113/1000], Batch [1/1], Discriminator Loss: 0.3868436813354492, Generator Loss: 2.9483954906463623\n",
            "Epoch [114/1000], Batch [1/1], Discriminator Loss: 0.39920878410339355, Generator Loss: 3.016266345977783\n",
            "Epoch [115/1000], Batch [1/1], Discriminator Loss: 0.3947669267654419, Generator Loss: 3.1000359058380127\n",
            "Epoch [116/1000], Batch [1/1], Discriminator Loss: 0.37828660011291504, Generator Loss: 2.8674206733703613\n",
            "Epoch [117/1000], Batch [1/1], Discriminator Loss: 0.37158364057540894, Generator Loss: 3.4178571701049805\n",
            "Epoch [118/1000], Batch [1/1], Discriminator Loss: 0.3540450632572174, Generator Loss: 2.5500853061676025\n",
            "Epoch [119/1000], Batch [1/1], Discriminator Loss: 0.3568364977836609, Generator Loss: 3.9122350215911865\n",
            "Epoch [120/1000], Batch [1/1], Discriminator Loss: 0.350006639957428, Generator Loss: 2.3101561069488525\n",
            "Epoch [121/1000], Batch [1/1], Discriminator Loss: 0.40506526827812195, Generator Loss: 4.540882587432861\n",
            "Epoch [122/1000], Batch [1/1], Discriminator Loss: 0.3947463035583496, Generator Loss: 2.4950551986694336\n",
            "Epoch [123/1000], Batch [1/1], Discriminator Loss: 0.34606069326400757, Generator Loss: 3.8923516273498535\n",
            "Epoch [124/1000], Batch [1/1], Discriminator Loss: 0.2634759843349457, Generator Loss: 3.3613173961639404\n",
            "Epoch [125/1000], Batch [1/1], Discriminator Loss: 0.24671106040477753, Generator Loss: 3.0572783946990967\n",
            "Epoch [126/1000], Batch [1/1], Discriminator Loss: 0.2789660692214966, Generator Loss: 3.8415753841400146\n",
            "Epoch [127/1000], Batch [1/1], Discriminator Loss: 0.30732622742652893, Generator Loss: 2.421133279800415\n",
            "Epoch [128/1000], Batch [1/1], Discriminator Loss: 0.36266830563545227, Generator Loss: 4.7344465255737305\n",
            "Epoch [129/1000], Batch [1/1], Discriminator Loss: 0.4138588011264801, Generator Loss: 1.946631669998169\n",
            "Epoch [130/1000], Batch [1/1], Discriminator Loss: 0.4411360025405884, Generator Loss: 4.9588398933410645\n",
            "Epoch [131/1000], Batch [1/1], Discriminator Loss: 0.34695351123809814, Generator Loss: 3.496068000793457\n",
            "Epoch [132/1000], Batch [1/1], Discriminator Loss: 0.2147403061389923, Generator Loss: 2.8466575145721436\n",
            "Epoch [133/1000], Batch [1/1], Discriminator Loss: 0.2622060775756836, Generator Loss: 4.177032947540283\n",
            "Epoch [134/1000], Batch [1/1], Discriminator Loss: 0.2601841688156128, Generator Loss: 2.9682891368865967\n",
            "Epoch [135/1000], Batch [1/1], Discriminator Loss: 0.2615206837654114, Generator Loss: 3.7943115234375\n",
            "Epoch [136/1000], Batch [1/1], Discriminator Loss: 0.24799072742462158, Generator Loss: 3.100024700164795\n",
            "Epoch [137/1000], Batch [1/1], Discriminator Loss: 0.26590704917907715, Generator Loss: 3.730220079421997\n",
            "Epoch [138/1000], Batch [1/1], Discriminator Loss: 0.2663017213344574, Generator Loss: 2.6021368503570557\n",
            "Epoch [139/1000], Batch [1/1], Discriminator Loss: 0.33198052644729614, Generator Loss: 4.895485877990723\n",
            "Epoch [140/1000], Batch [1/1], Discriminator Loss: 0.4317675828933716, Generator Loss: 1.3764134645462036\n",
            "Epoch [141/1000], Batch [1/1], Discriminator Loss: 0.7484441995620728, Generator Loss: 7.562419414520264\n",
            "Epoch [142/1000], Batch [1/1], Discriminator Loss: 1.243977427482605, Generator Loss: 2.53143048286438\n",
            "Epoch [143/1000], Batch [1/1], Discriminator Loss: 0.3369443416595459, Generator Loss: 3.953925132751465\n",
            "Epoch [144/1000], Batch [1/1], Discriminator Loss: 0.2558814585208893, Generator Loss: 3.6839940547943115\n",
            "Epoch [145/1000], Batch [1/1], Discriminator Loss: 0.25989609956741333, Generator Loss: 3.1487531661987305\n",
            "Epoch [146/1000], Batch [1/1], Discriminator Loss: 0.28770604729652405, Generator Loss: 4.126490116119385\n",
            "Epoch [147/1000], Batch [1/1], Discriminator Loss: 0.26668089628219604, Generator Loss: 3.210235118865967\n",
            "Epoch [148/1000], Batch [1/1], Discriminator Loss: 0.28119421005249023, Generator Loss: 4.129711627960205\n",
            "Epoch [149/1000], Batch [1/1], Discriminator Loss: 0.27039387822151184, Generator Loss: 3.2566559314727783\n",
            "Epoch [150/1000], Batch [1/1], Discriminator Loss: 0.29157018661499023, Generator Loss: 4.131659030914307\n",
            "Epoch [151/1000], Batch [1/1], Discriminator Loss: 0.3019927144050598, Generator Loss: 2.6834828853607178\n",
            "Epoch [152/1000], Batch [1/1], Discriminator Loss: 0.3827378451824188, Generator Loss: 5.947266578674316\n",
            "Epoch [153/1000], Batch [1/1], Discriminator Loss: 0.757110595703125, Generator Loss: 0.501247763633728\n",
            "Epoch [154/1000], Batch [1/1], Discriminator Loss: 1.6820956468582153, Generator Loss: 9.280600547790527\n",
            "Epoch [155/1000], Batch [1/1], Discriminator Loss: 1.7959250211715698, Generator Loss: 5.794544219970703\n",
            "Epoch [156/1000], Batch [1/1], Discriminator Loss: 0.10814835131168365, Generator Loss: 3.082688808441162\n",
            "Epoch [157/1000], Batch [1/1], Discriminator Loss: 0.20154739916324615, Generator Loss: 3.4407224655151367\n",
            "Epoch [158/1000], Batch [1/1], Discriminator Loss: 0.15614917874336243, Generator Loss: 4.632602214813232\n",
            "Epoch [159/1000], Batch [1/1], Discriminator Loss: 0.12290078401565552, Generator Loss: 4.377946376800537\n",
            "Epoch [160/1000], Batch [1/1], Discriminator Loss: 0.15634894371032715, Generator Loss: 3.371427297592163\n",
            "Epoch [161/1000], Batch [1/1], Discriminator Loss: 0.2154163122177124, Generator Loss: 3.6164934635162354\n",
            "Epoch [162/1000], Batch [1/1], Discriminator Loss: 0.230525940656662, Generator Loss: 3.6445822715759277\n",
            "Epoch [163/1000], Batch [1/1], Discriminator Loss: 0.27432912588119507, Generator Loss: 3.2370283603668213\n",
            "Epoch [164/1000], Batch [1/1], Discriminator Loss: 0.3201093077659607, Generator Loss: 3.650947093963623\n",
            "Epoch [165/1000], Batch [1/1], Discriminator Loss: 0.3466700315475464, Generator Loss: 3.0918703079223633\n",
            "Epoch [166/1000], Batch [1/1], Discriminator Loss: 0.39005371928215027, Generator Loss: 4.308281421661377\n",
            "Epoch [167/1000], Batch [1/1], Discriminator Loss: 0.41259798407554626, Generator Loss: 1.9417502880096436\n",
            "Epoch [168/1000], Batch [1/1], Discriminator Loss: 0.7888931632041931, Generator Loss: 8.347558975219727\n",
            "Epoch [169/1000], Batch [1/1], Discriminator Loss: 1.6549468040466309, Generator Loss: 1.8024276494979858\n",
            "Epoch [170/1000], Batch [1/1], Discriminator Loss: 0.8179681897163391, Generator Loss: 5.83550500869751\n",
            "Epoch [171/1000], Batch [1/1], Discriminator Loss: 0.37894949316978455, Generator Loss: 4.421432971954346\n",
            "Epoch [172/1000], Batch [1/1], Discriminator Loss: 0.2024933099746704, Generator Loss: 3.019835948944092\n",
            "Epoch [173/1000], Batch [1/1], Discriminator Loss: 0.4290660619735718, Generator Loss: 5.2335124015808105\n",
            "Epoch [174/1000], Batch [1/1], Discriminator Loss: 0.39133220911026, Generator Loss: 3.3861849308013916\n",
            "Epoch [175/1000], Batch [1/1], Discriminator Loss: 0.37043923139572144, Generator Loss: 4.0393195152282715\n",
            "Epoch [176/1000], Batch [1/1], Discriminator Loss: 0.3611912131309509, Generator Loss: 3.3621878623962402\n",
            "Epoch [177/1000], Batch [1/1], Discriminator Loss: 0.3952433466911316, Generator Loss: 4.208549976348877\n",
            "Epoch [178/1000], Batch [1/1], Discriminator Loss: 0.40074434876441956, Generator Loss: 2.7066032886505127\n",
            "Epoch [179/1000], Batch [1/1], Discriminator Loss: 0.5183342695236206, Generator Loss: 6.369770526885986\n",
            "Epoch [180/1000], Batch [1/1], Discriminator Loss: 0.9315332770347595, Generator Loss: 0.813991904258728\n",
            "Epoch [181/1000], Batch [1/1], Discriminator Loss: 1.581108570098877, Generator Loss: 9.53369426727295\n",
            "Epoch [182/1000], Batch [1/1], Discriminator Loss: 1.9472358226776123, Generator Loss: 4.924352645874023\n",
            "Epoch [183/1000], Batch [1/1], Discriminator Loss: 0.12607133388519287, Generator Loss: 2.1402063369750977\n",
            "Epoch [184/1000], Batch [1/1], Discriminator Loss: 0.7780347466468811, Generator Loss: 7.351802825927734\n",
            "Epoch [185/1000], Batch [1/1], Discriminator Loss: 0.572670042514801, Generator Loss: 4.965245723724365\n",
            "Epoch [186/1000], Batch [1/1], Discriminator Loss: 0.1890966147184372, Generator Loss: 2.7012991905212402\n",
            "Epoch [187/1000], Batch [1/1], Discriminator Loss: 0.6090543866157532, Generator Loss: 6.463041305541992\n",
            "Epoch [188/1000], Batch [1/1], Discriminator Loss: 0.8074108362197876, Generator Loss: 2.3984806537628174\n",
            "Epoch [189/1000], Batch [1/1], Discriminator Loss: 0.696387529373169, Generator Loss: 5.910465717315674\n",
            "Epoch [190/1000], Batch [1/1], Discriminator Loss: 0.5848644971847534, Generator Loss: 3.001967430114746\n",
            "Epoch [191/1000], Batch [1/1], Discriminator Loss: 0.5577068328857422, Generator Loss: 5.122106075286865\n",
            "Epoch [192/1000], Batch [1/1], Discriminator Loss: 0.49111706018447876, Generator Loss: 2.7258124351501465\n",
            "Epoch [193/1000], Batch [1/1], Discriminator Loss: 0.7047457695007324, Generator Loss: 6.333169937133789\n",
            "Epoch [194/1000], Batch [1/1], Discriminator Loss: 1.0325261354446411, Generator Loss: 1.2236415147781372\n",
            "Epoch [195/1000], Batch [1/1], Discriminator Loss: 1.494602084159851, Generator Loss: 8.042642593383789\n",
            "Epoch [196/1000], Batch [1/1], Discriminator Loss: 1.4214820861816406, Generator Loss: 3.5755720138549805\n",
            "Epoch [197/1000], Batch [1/1], Discriminator Loss: 0.29138368368148804, Generator Loss: 2.8528196811676025\n",
            "Epoch [198/1000], Batch [1/1], Discriminator Loss: 0.49250978231430054, Generator Loss: 5.86310338973999\n",
            "Epoch [199/1000], Batch [1/1], Discriminator Loss: 0.5240476131439209, Generator Loss: 3.3914480209350586\n",
            "Epoch [200/1000], Batch [1/1], Discriminator Loss: 0.4071979224681854, Generator Loss: 3.741368293762207\n",
            "Epoch [201/1000], Batch [1/1], Discriminator Loss: 0.3904162645339966, Generator Loss: 3.9498016834259033\n",
            "Epoch [202/1000], Batch [1/1], Discriminator Loss: 0.46549367904663086, Generator Loss: 2.7991654872894287\n",
            "Epoch [203/1000], Batch [1/1], Discriminator Loss: 0.5811635851860046, Generator Loss: 4.784338474273682\n",
            "Epoch [204/1000], Batch [1/1], Discriminator Loss: 0.7366383671760559, Generator Loss: 1.0933979749679565\n",
            "Epoch [205/1000], Batch [1/1], Discriminator Loss: 1.3156288862228394, Generator Loss: 8.14728832244873\n",
            "Epoch [206/1000], Batch [1/1], Discriminator Loss: 1.9239938259124756, Generator Loss: 2.6121110916137695\n",
            "Epoch [207/1000], Batch [1/1], Discriminator Loss: 0.44677191972732544, Generator Loss: 2.807431936264038\n",
            "Epoch [208/1000], Batch [1/1], Discriminator Loss: 0.394157350063324, Generator Loss: 4.81214714050293\n",
            "Epoch [209/1000], Batch [1/1], Discriminator Loss: 0.4141060411930084, Generator Loss: 3.21380352973938\n",
            "Epoch [210/1000], Batch [1/1], Discriminator Loss: 0.3770030736923218, Generator Loss: 3.06889009475708\n",
            "Epoch [211/1000], Batch [1/1], Discriminator Loss: 0.4118044972419739, Generator Loss: 3.8607423305511475\n",
            "Epoch [212/1000], Batch [1/1], Discriminator Loss: 0.451747328042984, Generator Loss: 2.502772331237793\n",
            "Epoch [213/1000], Batch [1/1], Discriminator Loss: 0.5453671813011169, Generator Loss: 4.4309892654418945\n",
            "Epoch [214/1000], Batch [1/1], Discriminator Loss: 0.6081745028495789, Generator Loss: 1.600230097770691\n",
            "Epoch [215/1000], Batch [1/1], Discriminator Loss: 0.8259028792381287, Generator Loss: 6.526742458343506\n",
            "Epoch [216/1000], Batch [1/1], Discriminator Loss: 1.0730056762695312, Generator Loss: 2.14774751663208\n",
            "Epoch [217/1000], Batch [1/1], Discriminator Loss: 0.5323433876037598, Generator Loss: 4.491758346557617\n",
            "Epoch [218/1000], Batch [1/1], Discriminator Loss: 0.3033819794654846, Generator Loss: 3.6454246044158936\n",
            "Epoch [219/1000], Batch [1/1], Discriminator Loss: 0.27187010645866394, Generator Loss: 3.0687196254730225\n",
            "Epoch [220/1000], Batch [1/1], Discriminator Loss: 0.3722209930419922, Generator Loss: 4.502517223358154\n",
            "Epoch [221/1000], Batch [1/1], Discriminator Loss: 0.4249049425125122, Generator Loss: 2.373286724090576\n",
            "Epoch [222/1000], Batch [1/1], Discriminator Loss: 0.6281353235244751, Generator Loss: 6.233286380767822\n",
            "Epoch [223/1000], Batch [1/1], Discriminator Loss: 1.180834174156189, Generator Loss: 0.5033758282661438\n",
            "Epoch [224/1000], Batch [1/1], Discriminator Loss: 2.0978317260742188, Generator Loss: 8.816681861877441\n",
            "Epoch [225/1000], Batch [1/1], Discriminator Loss: 2.4621548652648926, Generator Loss: 3.6366450786590576\n",
            "Epoch [226/1000], Batch [1/1], Discriminator Loss: 0.25623857975006104, Generator Loss: 2.3703560829162598\n",
            "Epoch [227/1000], Batch [1/1], Discriminator Loss: 0.634872555732727, Generator Loss: 6.8273606300354\n",
            "Epoch [228/1000], Batch [1/1], Discriminator Loss: 0.855043888092041, Generator Loss: 2.6840291023254395\n",
            "Epoch [229/1000], Batch [1/1], Discriminator Loss: 0.5206265449523926, Generator Loss: 4.556858062744141\n",
            "Epoch [230/1000], Batch [1/1], Discriminator Loss: 0.3086729347705841, Generator Loss: 3.747220039367676\n",
            "Epoch [231/1000], Batch [1/1], Discriminator Loss: 0.3626549243927002, Generator Loss: 3.0205540657043457\n",
            "Epoch [232/1000], Batch [1/1], Discriminator Loss: 0.4717186689376831, Generator Loss: 4.438611030578613\n",
            "Epoch [233/1000], Batch [1/1], Discriminator Loss: 0.5567940473556519, Generator Loss: 1.7415579557418823\n",
            "Epoch [234/1000], Batch [1/1], Discriminator Loss: 0.8702544569969177, Generator Loss: 7.361945152282715\n",
            "Epoch [235/1000], Batch [1/1], Discriminator Loss: 1.7057228088378906, Generator Loss: 1.3201559782028198\n",
            "Epoch [236/1000], Batch [1/1], Discriminator Loss: 0.9914535284042358, Generator Loss: 6.226251602172852\n",
            "Epoch [237/1000], Batch [1/1], Discriminator Loss: 0.6850301027297974, Generator Loss: 3.739331007003784\n",
            "Epoch [238/1000], Batch [1/1], Discriminator Loss: 0.2195599228143692, Generator Loss: 2.682526111602783\n",
            "Epoch [239/1000], Batch [1/1], Discriminator Loss: 0.4160822629928589, Generator Loss: 5.040369987487793\n",
            "Epoch [240/1000], Batch [1/1], Discriminator Loss: 0.35749685764312744, Generator Loss: 3.4948344230651855\n",
            "Epoch [241/1000], Batch [1/1], Discriminator Loss: 0.34210240840911865, Generator Loss: 3.1022276878356934\n",
            "Epoch [242/1000], Batch [1/1], Discriminator Loss: 0.4421926736831665, Generator Loss: 4.230817794799805\n",
            "Epoch [243/1000], Batch [1/1], Discriminator Loss: 0.5289453864097595, Generator Loss: 2.0364136695861816\n",
            "Epoch [244/1000], Batch [1/1], Discriminator Loss: 0.7487442493438721, Generator Loss: 5.988317012786865\n",
            "Epoch [245/1000], Batch [1/1], Discriminator Loss: 0.9719821810722351, Generator Loss: 1.969393014907837\n",
            "Epoch [246/1000], Batch [1/1], Discriminator Loss: 0.6296907663345337, Generator Loss: 4.682406425476074\n",
            "Epoch [247/1000], Batch [1/1], Discriminator Loss: 0.30453047156333923, Generator Loss: 4.131606101989746\n",
            "Epoch [248/1000], Batch [1/1], Discriminator Loss: 0.24916906654834747, Generator Loss: 2.970332145690918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate images\n",
        "num_samples = 10 # Number of images to generate\n",
        "noise = torch.randn(num_samples, input_size).to(device) # Generate random noise\n",
        "features = feature_data[0:num_samples] # Feature inputs\n",
        "features = torch.from_numpy(features)\n",
        "generated_images = gan.generator(noise, features).detach().cpu()\n",
        "\n",
        "# Display generated images\n",
        "fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
        "\n",
        "for i, image in enumerate(generated_images):\n",
        "    axes[i].imshow(image.permute(1, 2, 0))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-N8nSy0ht31h"
      },
      "id": "-N8nSy0ht31h",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}